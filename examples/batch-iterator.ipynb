{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will explore how to read a simple Lightning Memory-Mapped Database (LMDB) with `pyxis` using iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pyxis as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency, we will be using a random number generator with a seed for some of the iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a small dataset of `10` samples. Each input is a randomly generated image with shape `(254, 254, 3)`, while the targets are scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 10\n",
    "\n",
    "X = rng.rand(nb_samples, 254, 254, 3)\n",
    "y = np.arange(nb_samples, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is written using the `pyxis` writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = px.Writer(dirpath='data', map_size_limit=30, ram_gb_limit=1)\n",
    "db.put_samples('X', X, 'y', y)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using batch iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back the data using the `pyxis` reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = px.Reader('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example 1 - Number of samples is a multiple of the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first example we create a (simple) batch iterator where the number of samples is divisible by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = px.SimpleBatch(db, keys=('X', 'y'), batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the iterators that come with `pyxis` have the mandatory `keys` argument. The data returned by the iterator will be the values for which these keys point to. The order of the keys matter. For example, when using the keys `('a', 'b')` the iterator will return `(a_val, b_val)`, where `a_val` and `b_val` are the values associated with the keys `'a'` and `'b'`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artificial dataset has `10` samples, so by letting the batch size be `5` it will take *two* iterations to go through the whole dataset. The artificial targets for four batches are printed out to showcase this.\n",
    "\n",
    "`endless` is by default on, which means that after having gone through the dataset, the iterator will re-iterate over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0 \tTargets: [0 1 2 3 4]\n",
      "\n",
      "Iteration: 1 \tTargets: [5 6 7 8 9]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 2 \tTargets: [0 1 2 3 4]\n",
      "\n",
      "Iteration: 3 \tTargets: [5 6 7 8 9]\n",
      "We have reached the end of the dataset\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    xs, ys = next(gen)\n",
    "    print()\n",
    "    print('Iteration:', i, '\\tTargets:', ys)\n",
    "    if gen.end_of_dataset:\n",
    "        print('We have reached the end of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Number of samples is not a multiple of the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = px.SimpleBatch(db, keys=('X', 'y'), batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artificial dataset has `10` samples, so by letting the batch size be `3` it will take four iterations to go through the whole dataset. The artificial targets for *six* batches are printed out to showcase this.\n",
    "\n",
    "Notice that the final batch of the dataset only contains the remaining unseen samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0 \tTargets: [0 1 2]\n",
      "\n",
      "Iteration: 1 \tTargets: [3 4 5]\n",
      "\n",
      "Iteration: 2 \tTargets: [6 7 8]\n",
      "\n",
      "Iteration: 3 \tTargets: [9]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 4 \tTargets: [0 1 2]\n",
      "\n",
      "Iteration: 5 \tTargets: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    xs, ys = next(gen)\n",
    "    print()\n",
    "    print('Iteration:', i, '\\tTargets:', ys)\n",
    "    if gen.end_of_dataset:\n",
    "        print('We have reached the end of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 - Shuffling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have created batches by reading samples from the dataset in the order they were written. However, by turning shuffling on, the samples in the dataset will be reshuffled each time we go through the dataset.\n",
    "\n",
    "Notice how we only request the values for the `y` key this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = px.SimpleBatch(db, keys=('y'), batch_size=5, shuffle=True, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0 \tTargets: [6 2 0 1 8]\n",
      "\n",
      "Iteration: 1 \tTargets: [7 3 5 4 9]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 2 \tTargets: [2 7 3 8 4]\n",
      "\n",
      "Iteration: 3 \tTargets: [1 5 0 9 6]\n",
      "We have reached the end of the dataset\n",
      "\n",
      "Iteration: 4 \tTargets: [8 2 4 7 3]\n",
      "\n",
      "Iteration: 5 \tTargets: [0 1 6 5 9]\n",
      "We have reached the end of the dataset\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    ys = next(gen)\n",
    "    print()\n",
    "    print('Iteration:', i, '\\tTargets:', ys)\n",
    "    if gen.end_of_dataset:\n",
    "        print('We have reached the end of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4 - Stochastic batch iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batches can be created stochastically. This means that the samples in a batch are sampled uniformly from the entire dataset. Here we showcase *ten* different batches with a batch size of *five*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = px.StochasticBatch(db, keys=('y'), batch_size=5, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \tTargets: [2 6 3 3 4]\n",
      "Iteration: 1 \tTargets: [9 4 8 0 4]\n",
      "Iteration: 2 \tTargets: [3 2 2 4 4]\n",
      "Iteration: 3 \tTargets: [9 9 1 5 0]\n",
      "Iteration: 4 \tTargets: [3 9 4 1 5]\n",
      "Iteration: 5 \tTargets: [4 5 7 6 5]\n",
      "Iteration: 6 \tTargets: [8 6 6 2 0]\n",
      "Iteration: 7 \tTargets: [7 2 1 0 9]\n",
      "Iteration: 8 \tTargets: [1 5 6 0 7]\n",
      "Iteration: 9 \tTargets: [8 9 1 3 7]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ys = next(gen)\n",
    "    print('Iteration:', i, '\\tTargets:', ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5 - Sequential batch iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batches can be created by reading the database sequentially. This means that the samples in a batch are not shuffled, but can be read at a higher speed. The sequential batch iterator is ideal for very large datasets. Here we showcase ten different batches with a batch size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = px.SequentialBatch(db, keys=('y'), batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \tTargets: [0 1 2]\n",
      "Iteration: 1 \tTargets: [3 4 5]\n",
      "Iteration: 2 \tTargets: [6 7 8]\n",
      "Iteration: 3 \tTargets: [9]\n",
      "Iteration: 4 \tTargets: [0 1 2]\n",
      "Iteration: 5 \tTargets: [3 4 5]\n",
      "Iteration: 6 \tTargets: [6 7 8]\n",
      "Iteration: 7 \tTargets: [9]\n",
      "Iteration: 8 \tTargets: [0 1 2]\n",
      "Iteration: 9 \tTargets: [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ys = next(gen)\n",
    "    print('Iteration:', i, '\\tTargets:', ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6 - Thread-safe iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three types of iterators demonstrated so far are:\n",
    "\n",
    "* `pyxis.SimpleBatch`\n",
    "* `pyxis.StochasticBatch`\n",
    "* `pyxis.SequentialBatch`\n",
    "\n",
    "Each of these come with a *thread-safe* variant. By *thread-safe* we mean that when more than one thread make use of the iterator it will not raise an exception. These variants have the suffix `ThreadSafe`:\n",
    "\n",
    "* `pyxis.SimpleBatchThreadSafe`\n",
    "* `pyxis.StochasticBatchThreadSafe`\n",
    "* `pyxis.SequentialBatchThreadSafe`\n",
    "\n",
    "Other than being *thread-safe*, they work exactly the same as the *non-thread-safe* versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the types of iterators demonstrated above will always yield data as they were stored in the LMDB.\n",
    "\n",
    "To create an iterator that modifies the data we can, for example, modify one of the existing iterators using inheritance. Here is an example where all *targets* are squared before they are output by the iterator. Notice how thread-safety is achieved by using the ``with`` statement with the Python lock object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareTargets(px.SimpleBatchThreadSafe):\n",
    "    def __init__(self, db, keys, batch_size):\n",
    "        super(SquareTargets, self).__init__(db, keys, batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            endless=False)\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            X, y = next(self.gen)\n",
    "\n",
    "        y = y ** 2\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``SquareTargets`` can now be used to generate batches of data from the LMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared targets:\n",
      "[0 1]\n",
      "[4 9]\n",
      "[16 25]\n",
      "[36 49]\n",
      "[64 81]\n"
     ]
    }
   ],
   "source": [
    "gen = SquareTargets(db, keys=('X', 'y'), batch_size=2)\n",
    "\n",
    "print('Squared targets:')\n",
    "for _, y in gen:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure to close the LMDB environment after we are done reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
